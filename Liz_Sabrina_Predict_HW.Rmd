---
title: "MUSA 508 Predicting Risk HW"
author: "Liz Williams"
date: "October 23rd, 2020"
output:
  html_document:
    toc: true
    toc_float: true
---

# Introduction 
For this project, we are building a geospatial risk predictive model of robberies that occur in D.C. We perform data wrangling on robberies and other risk factor data into geospatial features, correlate the exposure to risk factors and robberies, and then estimate models to predict robberies latent risk. The models are then validated in part by comparing predictions to a standard, business-as-usual measure of geospatial crime risk. The model uses past 2017 robberies data from the city of D.C. to predict future locations of robberies. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)

library(tidyverse)
library(sf)
library(RSocrata)
library(viridis)
library(spatstat)
library(raster)
library(spdep)
library(FNN)
library(grid)
library(gridExtra)
library(knitr)
library(kableExtra)
library(tidycensus)
library(spatstat)
library(dplyr, warn.conflicts = FALSE)

# Suppress summarise info
options(dplyr.summarise.inform = FALSE)

# functions
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

qBr <- function(df, variable, rnd) {
  if (missing(rnd)) {
    as.character(quantile(round(df[[variable]],0),
                          c(.01,.2,.4,.6,.8), na.rm=T))
  } else if (rnd == FALSE | rnd == F) {
    as.character(formatC(quantile(df[[variable]]), digits = 3),
                 c(.01,.2,.4,.6,.8), na.rm=T)
  }
}
q5 <- function(variable) {as.factor(ntile(variable, 5))}

palette5 <- c("#f0f9e8","#bae4bc","#7bccc4","#43a2ca","#0868ac")

nn_function <- function(measureFrom,measureTo,k) {
  measureFrom_Matrix <-
    as.matrix(measureFrom)
  measureTo_Matrix <-
    as.matrix(measureTo)
  nn <-   
    get.knnx(measureTo, measureFrom, k)$nn.dist
    output <-
      as.data.frame(nn) %>%
      rownames_to_column(var = "thisPoint") %>%
      gather(points, point_distance, V1:ncol(.)) %>%
      arrange(as.numeric(thisPoint)) %>%
      group_by(thisPoint) %>%
      summarize(pointDistance = mean(point_distance)) %>%
      arrange(as.numeric(thisPoint)) %>% 
      dplyr::select(-thisPoint) %>%
      pull()
  
  return(output)  
}

## Load API Key - Liz
census_api_key("d8b938a81d19a2811d021f339295fbf6135f7d36", overwrite = TRUE)

## Load API Key - Sabrina 
census_api_key("30bae866445f7bea5ea57b8f5fba60b11b8b145e", overwrite = TRUE)
```

# Data Wrangling
We use the R Socrata package to load data from the D.C. Open Data Portal, including police service areas, D.C. city boundaries, robberies and risk factors. 

```{r setup, include=FALSE}

robberies <- st_read("https://opendata.arcgis.com/datasets/6af5cb8dc38e4bcbac8168b27ee104aa_38.geojson") %>%
  filter(OFFENSE == "ROBBERY") %>%
  mutate(LATITUDE = as.numeric(LATITUDE),LONGITUDE = as.numeric(LONGITUDE)) %>% 
  dplyr::select(LATITUDE, LONGITUDE) %>%
  na.omit() %>%
  st_as_sf(coords = c("LATITUDE", "LONGITUDE"), crs = 4326, agr = "constant")%>%
  st_transform('ESRI:102685') %>%
  distinct()

DCboundary <- st_read("https://opendata.arcgis.com/datasets/7241f6d500b44288ad983f0942b39663_10.geojson") %>%
    st_transform('ESRI:102685')
  
PoliceServiceAreas <- st_read("https://opendata.arcgis.com/datasets/db24f3b7de994501aea97ce05a50547e_10.geojson") %>%
    st_transform('ESRI:102685')

tracts17 <- 
  get_acs(geography = "tract", variables = c("B01001_001E","B01001A_001E","B06011_001"), 
          year = 2017, state=11, geometry=T, output = "wide") %>%
  st_transform(st_crs(DCboundary))  %>%
  rename(TotalPop = B01001_001E,
         NumberWhites = B01001A_001E,
         Median_Income = B06011_001E) %>%
  mutate(percentWhite = ((NumberWhites / TotalPop)*100),
         raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
         incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"))

tracts18 <- 
  get_acs(geography = "tract", variables = c("B01001_001E","B01001A_001E","B06011_001"), 
          year = 2018, state=11, geometry=T, output = "wide") %>%
  st_transform(st_crs(DCboundary))  %>%
  rename(TotalPop = B01001_001E,
         NumberWhites = B01001A_001E,
         Median_Income = B06011_001E) %>%
  mutate(percentWhite = ((NumberWhites / TotalPop)*100),
         raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
         incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"))

requests311 <- st_read("https://opendata.arcgis.com/datasets/19905e2b0e1140ec9ce8437776feb595_8.geojson") %>%
    st_transform('ESRI:102685')

graffiti <- requests311 %>%
  filter(SERVICECODEDESCRIPTION == "Graffiti Removal") %>%
  dplyr::select(geometry) %>%
  mutate(Legend = "Graffiti_Removal")

streetlights <- requests311 %>%
  filter(SERVICECODEDESCRIPTION == "Streetlight Repair Investigation") %>%
  dplyr::select(geometry) %>%
  mutate(Legend = "Streelight_Out")

abandonedCar <- requests311 %>%
  filter(SERVICECODEDESCRIPTION %in% c("Abandoned Vehicle - On Public Property", "	
Abandoned Vehicle - On Private Property")) %>%
  dplyr::select(geometry) %>%
  mutate(Legend = "Abandoned_Car")

sanitation <- requests311 %>%
  filter(SERVICECODEDESCRIPTION == "Sanitation Enforcement") %>%
  dplyr::select(geometry) %>%
  mutate(Legend = "Sanitation")

illegalDumping <- requests311 %>%
  filter(SERVICECODEDESCRIPTION == "Illegal Dumping") %>%
  dplyr::select(geometry) %>%
  mutate(Legend = "Illegal_Dumping")

homelessServices <- requests311 %>%
  filter(SERVICECODEDESCRIPTION == "Homeless Services - Winter/Hypothermia Season") %>%
  dplyr::select(geometry) %>%
  mutate(Legend = "Homeless_Services")

gunshots <- st_read("https://opendata.arcgis.com/datasets/89bfd2aed9a142249225a638448a5276_29.geojson") %>%
    st_transform('ESRI:102685') %>%
    dplyr::select(geometry) %>%
    mutate(Legend = "Gun_Shots")

green_spaces <- st_read("https://opendata.arcgis.com/datasets/9927e456ac024b11811323812934edbb_12.geojson") %>%
    st_transform('ESRI:102685') %>%
    dplyr::select(geometry) %>%
    mutate(Legend = "Green_Space")

police_stations <- st_read("https://opendata.arcgis.com/datasets/9e465c1e6dfd4605a7632ed5737644f3_11.geojson")%>%
    st_transform('ESRI:102685')

neighborhoods <- st_read("https://opendata.arcgis.com/datasets/f6c703ebe2534fc3800609a07bad8f5b_17.geojson") %>%
    st_transform('ESRI:102685')

public_housing_areas <- st_read("https://opendata.arcgis.com/datasets/7f40eee5afaa4210959c2a55328a0cab_15.geojson") %>%
    st_transform('ESRI:102685') 

liquor_licenses <- st_read("https://opendata.arcgis.com/datasets/cabe9dcef0b344518c7fae1a3def7de1_5.geojson") %>%
    st_transform('ESRI:102685') %>%
    dplyr::select(geometry) %>%
    mutate(Legend = "liquor_licenses")



```

# Creating the fishnet
We create a fishnet with 500 x 500 foot grid cells. The fishnet is used to treat crime risk as a phenomenon that varies across space, and to aggregate point-level data. 
```{r}
## using {sf} to create the grid
## Note the `.[DCBoundary] %>% ` line. This is needed to clip the grid to our data
fishnet <- 
  st_make_grid(DCboundary,
               cellsize = 500, 
               square = TRUE) %>%
  #.[DCboundary] %>% ## had to add (not in book?) - gets rid of those things in box not intersecting boundary
  st_sf() %>%
  mutate(uniqueID = rownames(.))
```

# Visualizing robberies in D.C. in 2017, and what, when, and why selection bias may be an issue.
The maps below show the location of robberies that occurred in D.C. in 2017. There appears to be a greater density of robberies happening in the central and eastern parts of the city. 
There is likely to be selection bias happening, because incidents of robberies shown on the map are dependent on the reporting of suspected robberies. In some areas/ neighborhoods, residents may be more likely to report on robberies than in other areas, which would result in a higher density of robberies that are seen in those areas. There might also be higher incidences of robberies in areas that are more surveilled/ policed compared to others. 

```{r}
ggplot() + 
  geom_sf(data=DCboundary) +
  geom_sf(data=robberies, size=.7) +
  labs(title = "DC Robberies in 2017") +
  mapTheme()

ggplot(tracts17) + 
  geom_sf(aes(fill = q5(percentWhite))) +
  geom_sf(data=robberies, size=.4) +
  scale_fill_manual(values = palette5,labels = qBr(tracts17, "percentWhite"),name = "Percent White\n(Quintile Breaks)") +
  labs(title = "DC Robberies in 2017") +
  mapTheme()

```

# Joined robberies to fishnet
The figure below shows the count of robberies incidents within each grid cell of the fishnet. This allows us to use the fishnet grid to visualize clusters as robbery hotspots. There appears to be a higher concentration of yellow cells (with higher robbery count) in the central and eastern parts of the city, which corresponds to what we observed in the point data map shown above. 

```{r}
## add a value of 1 to each crime, sum them with aggregate
crime_net <- 
  dplyr::select(robberies) %>% 
  mutate(countRobberies = 1) %>% 
  aggregate(., fishnet, sum) %>%
  mutate(countRobberies = replace_na(countRobberies, 0),
         uniqueID = rownames(.),
         cvID = sample(round(nrow(fishnet) / 24), 
                       size=nrow(fishnet), replace = TRUE))

ggplot() +
  geom_sf(data = crime_net, aes(fill = countRobberies), color = NA) +
  scale_fill_viridis() +
  labs(title = "Count of 2017 Robberies Incidents for the fishnet") +
  mapTheme()
```

# A small multiple map of risk factors in the fishnet (counts, distance and/or other feature engineering approaches).
Here, risk factors that are deemed to be associated with robbery are identified and selected to build the model. We include the risk factors of abandoned cars, gunshots, sanitation levels, presence of street lights, graffiti, green spaces and establishments with liquor licenses. Selection bias is introduced here, because the selection of features reveal assumptions on what factors lead to higher robbery rates. 

The figure below shows the risk factors by fishnet, which illustrate the spatial processes of how these risk factors are clustered in the city. Liquour licenses and graffiti are mostly clustered in the city centre. Gunshots and abandoned cars appear more clustered in the eastern part of the city. 


```{r}

vars_net <- 
  rbind(abandonedCar, gunshots, sanitation, 
        streetlights, graffiti, green_spaces, liquor_licenses) %>%
  st_join(., fishnet, join=st_within) %>%
  st_drop_geometry() %>%
  group_by(uniqueID, Legend) %>%
  summarize(count = n()) %>%
    full_join(fishnet) %>%
    spread(Legend, count, fill=0) %>%
    st_sf() %>%
    dplyr::select(-`<NA>`) %>%
    na.omit() %>%
    ungroup()

vars_net.long <- 
  gather(vars_net, Variable, value, -geometry, -uniqueID)

vars <- unique(vars_net.long$Variable)
mapList <- list()

for(i in vars){
  mapList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(vars_net.long, Variable == i), aes(fill=value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme()}

do.call(grid.arrange,c(mapList, ncol =3, top = "Risk Factors by Fishnet"))

```

## nn distance 
The second feature engineering approach we use is to calculate the average nearest neighbor distance to hypothesize a smoother exposure relationship across space. 

```{r}
st_c <- st_coordinates
st_coid <- st_centroid
st_c_liquor_licenses <- st_c(liquor_licenses)
st_c_public_housing_areas <- st_c(public_housing_areas)

vars_net <-
  vars_net %>%
    mutate(
      abandonedCar.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(abandonedCar),3),
      gunshots.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(gunshots),3),
      graffiti.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(graffiti),3),
      green_spaces.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(green_spaces),3),
      streetlights.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(streetlights),3),
      sanitation.nn =
        nn_function(st_c(st_coid(vars_net)), st_c(sanitation),3),
      liquor_licenses.nn = 
        nn_function(st_c(st_coid(vars_net)), st_c_liquor_licenses,3))

vars_net.long.nn <- 
  dplyr::select(vars_net, ends_with(".nn")) %>%
    gather(Variable, value, -geometry)

vars <- unique(vars_net.long.nn$Variable)
mapList <- list()

for(i in vars){
  mapList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(vars_net.long.nn, Variable == i), aes(fill=value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme()}

do.call(grid.arrange,c(mapList, ncol = 3, top = "Nearest Neighbor risk Factors by Fishnet"))

```

## Add distance to downtown as a feature
Here, we measure the distance to the downtown as a feature, before creating the final net. 

```{r}
downtownPoint <-
  filter(neighborhoods, NAME == "Cluster 8") %>%
  st_centroid()

vars_net$downtownDistance =
  st_distance(st_centroid(vars_net),downtownPoint) %>%
  as.numeric() 

vars_net.long <- 
  gather(vars_net, Variable, value, -geometry, -uniqueID)

ggplot() +
      geom_sf(data = filter(vars_net.long, Variable == "downtownDistance"), aes(fill=value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title="Distance to downtown") +
      mapTheme()

```

## Create the final net
Here, we combine the crime data with the risk factor data and join the neighborhoods and police service areas to the final fishnet. 
```{r}
final_net <-
  left_join(crime_net, st_drop_geometry(vars_net), by="uniqueID") 

final_net <-
  st_centroid(final_net) %>%
    st_join(dplyr::select(neighborhoods, NBH_NAMES), by = "uniqueID") %>%
    st_join(dplyr::select(PoliceServiceAreas, PSA), by = "uniqueID") %>%
      st_drop_geometry() %>%
      left_join(dplyr::select(final_net, geometry, uniqueID)) %>%
      st_sf() %>%
  na.omit()
```

# Spatial Process of Dependent Variable (Robberies) 
## Local Moran's I-related small multiple map of robberies in DC 
We perform the local Moran's I to test for spatial autocorrelation at a local scale. 
The figures below plot test statistics from Local Moran's I, including I, the p-value, and significant hotspots, defined as those grid cells with higher local counts than what might otherwise be expected under randomness (p-values <= 0.05). The data frame is then converted to long form for mapping.

```{r}
final_net.nb <- poly2nb(as_Spatial(final_net), queen=TRUE)
final_net.weights <- nb2listw(final_net.nb, style="W", zero.policy=TRUE)

final_net.localMorans <- 
  cbind(
    as.data.frame(localmoran(final_net$countRobberies, final_net.weights)),
    as.data.frame(final_net)) %>% 
    st_sf() %>%
      dplyr::select(Robbery_Count = countRobberies, 
                    Local_Morans_I = Ii, 
                    P_Value = `Pr(z > 0)`) %>%
      mutate(Significant_Hotspots = ifelse(P_Value <= 0.01, 1, 0)) %>%
      gather(Variable, Value, -geometry)
  
vars <- unique(final_net.localMorans$Variable)
varList <- list()

for(i in vars){
  varList[[i]] <- 
    ggplot() +
      geom_sf(data = filter(final_net.localMorans, Variable == i), 
              aes(fill = Value), colour=NA) +
      scale_fill_viridis(name="") +
      labs(title=i) +
      mapTheme() + theme(legend.position="bottom")}

do.call(grid.arrange,c(varList, ncol = 4, top = "Local Morans I statistics, Burglary"))

```

Here, the null hypothesis is that the burglary count at a given location is randomly distributed relative to its immediate neighbors.

# A small multiple scatterplot with correlations.

```{r}
final_net <-
  final_net %>% 
  mutate(robbery.isSig = 
           ifelse(localmoran(final_net$countRobberies, 
                             final_net.weights)[,5] <= 0.0000001, 1, 0)) %>%
  mutate(robbery.isSig.dist = 
           nn_function(st_coordinates(st_centroid(final_net)),
                       st_coordinates(st_centroid(
                         filter(final_net, robbery.isSig == 1))), 1))
```


```{r, fig.width=5, fig.height=6}

correlation.long <-
  st_drop_geometry(final_net) %>%
    dplyr::select(-uniqueID, -cvID, -downtownDistance, -NBH_NAMES, -PSA) %>%
    gather(Variable, Value, -countRobberies)

correlation.cor <-
  correlation.long %>%
    group_by(Variable) %>%
    summarize(correlation = cor(Value, countRobberies, use = "complete.obs"))
    
ggplot(correlation.long, aes(Value, countRobberies)) +
  geom_point(size = 0.5) +
  facet_wrap(~Variable, ncol = 2, scales = "free") +
  geom_text(data = correlation.cor, aes(label = paste("r =", round(correlation, 2))),
            x=-Inf, y=Inf, vjust = 1.5, hjust = -.1) +
  geom_smooth(method = "lm", se = FALSE, colour = "orange") +
  facet_wrap(~Variable, ncol = 2, scales = "free") +
  labs(title = "Burglary count as a function of risk factors") +
  plotTheme()
```

# A histogram of your dependent variable.

```{r}

final_net %>%
  ggplot(aes(countRobberies)) + 
    geom_histogram(bins = 10, colour="black") +
  scale_x_continuous(breaks = seq(0, 5, by = 1)) + 
    labs(title="Distribution of Robbery Counts", 
         x="countRobberies", y="Count") 
```

# A small multiple map of model errors by random k-fold and spatial cross validation.
Here, we perform spatial cross-validation to determine the generalizability of our geospatial risk model. 

## Setup cross validation
```{r}

# Below, goodness of fit metrics are generated for four regressions - two including Just Risk Factors (reg.vars), and a second (reg.ss.vars) includes risk factors plus the Local Moran's I 

reg.vars <- c("abandonedCar.nn", "gunshots.nn", "graffiti.nn", 
              "green_spaces.nn", "streetlights.nn", "sanitation.nn", 
              "downtownDistance", "liquor_licenses.nn")

reg.ss.vars <- c("abandonedCar.nn", "gunshots.nn", "graffiti.nn", 
              "green_spaces.nn", "streetlights.nn", "sanitation.nn", 
              "downtownDistance","liquor_licenses.nn", "robbery.isSig", "robbery.isSig.dist")
```


```{r}

# setup cross validate function
crossValidate <- function(dataset, id, dependentVariable, indVariables) {

allPredictions <- data.frame()
cvID_list <- unique(dataset[[id]])

for (i in cvID_list) {

  thisFold <- i
  cat("This hold out fold is", thisFold, "\n")

  fold.train <- filter(dataset, dataset[[id]] != thisFold) %>% as.data.frame() %>% 
                dplyr::select(id, geometry, indVariables, dependentVariable)
  fold.test  <- filter(dataset, dataset[[id]] == thisFold) %>% as.data.frame() %>% 
                dplyr::select(id, geometry, indVariables, dependentVariable)
  
  regression <-
    glm(countRobberies ~ ., family = "poisson", 
      data = fold.train %>% 
      dplyr::select(-geometry, -id))
  
  thisPrediction <- 
    mutate(fold.test, Prediction = predict(regression, fold.test, type = "response"))
    
  allPredictions <-
    rbind(allPredictions, thisPrediction)
    
  }
  return(st_sf(allPredictions))
}
```

## Cross validation

```{r}
reg.cv <- crossValidate(
  dataset = final_net,
  id = "cvID",
  dependentVariable = "countRobberies",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = cvID, countRobberies, Prediction, geometry)

reg.ss.cv <- crossValidate(
  dataset = final_net,
  id = "cvID",
  dependentVariable = "countRobberies",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = cvID, countRobberies, Prediction, geometry)
  
reg.spatialCV <- crossValidate(
  dataset = final_net,
  id = "NBH_NAMES",
  dependentVariable = "countRobberies",
  indVariables = reg.vars) %>%
    dplyr::select(cvID = NBH_NAMES, countRobberies, Prediction, geometry)

reg.ss.spatialCV <- crossValidate(
  dataset = final_net,
  id = "NBH_NAMES",
  dependentVariable = "countRobberies",
  indVariables = reg.ss.vars) %>%
    dplyr::select(cvID = NBH_NAMES, countRobberies, Prediction, geometry)
```

## Cross validation metrics

```{r}
reg.summary <- 
  rbind(
    mutate(reg.cv,           Error = Prediction - countRobberies,
                             Regression = "Random k-fold CV: Just Risk Factors"),
                             
    mutate(reg.ss.cv,        Error = Prediction - countRobberies,
                             Regression = "Random k-fold CV: Spatial Process"),
    
    mutate(reg.spatialCV,    Error = Prediction - countRobberies,
                             Regression = "Spatial LOGO-CV: Just Risk Factors"),
                             
    mutate(reg.ss.spatialCV, Error = Prediction - countRobberies,
                             Regression = "Spatial LOGO-CV: Spatial Process")) %>%
    st_sf() 
```

```{r}
error_by_reg_and_fold <- 
  reg.summary %>%
    group_by(Regression, cvID) %>% 
    summarize(Mean_Error = mean(Prediction - countRobberies, na.rm = T),
              MAE = mean(abs(Mean_Error), na.rm = T),
              SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()

error_by_reg_and_fold %>%
  ggplot(aes(MAE)) + 
    geom_histogram(bins = 30, colour="black", fill = "#FDE725FF") +
    facet_wrap(~Regression) +  
    geom_vline(xintercept = 0) + scale_x_continuous(breaks = seq(0, 8, by = 1)) + 
    labs(title="Distribution of MAE", subtitle = "k-fold cross validation vs. LOGO-CV",
         x="Mean Absolute Error", y="Count") 
```


# A table of MAE and standard deviation MAE by regression.

```{r}
st_drop_geometry(error_by_reg_and_fold) %>%
  group_by(Regression) %>% 
    summarize(Mean_MAE = round(mean(MAE), 2),
              SD_MAE = round(sd(MAE), 2)) %>%
  kable(caption = "MAE by regression") %>%
    kable_styling("striped", full_width = F) %>%
    row_spec(2, color = "black", background = "#FDE725FF") %>%
    row_spec(4, color = "black", background = "#FDE725FF") 
```

# A table of raw errors by race context for a random k-fold vs. spatial cross validation regression.

```{r}
reg.summary %>% 
  filter(str_detect(Regression, "LOGO")) %>%
    st_centroid() %>%
    st_join(tracts18) %>%
    na.omit() %>%
      st_drop_geometry() %>%
      group_by(Regression, raceContext) %>%
      summarize(mean.Error = mean(Error, na.rm = T)) %>%
      spread(raceContext, mean.Error) %>%
      kable(caption = "Mean Error by neighborhood racial context") %>%
        kable_styling("striped", full_width = F) 
```


# The map comparing kernel density to risk predictions for the next year's crime.

```{r}
burg_ppp <- as.ppp(st_coordinates(robberies), W = st_bbox(final_net))

#spatstat.options(npixel=c(1000,1000))
burg_KD <- spatstat::density.ppp(burg_ppp, 1000)

as.data.frame(burg_KD) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) %>%
   ggplot(color=NA) +
     geom_sf(aes(fill=value)) +
     geom_sf(data = sample_n(robberies, 1500), size = .5) +
     scale_fill_viridis(name = "Density") +
     labs(title = "Kernel density of 2017 burglaries") +
     mapTheme()
```


```{r}
# Download 2018 robberies
robberies18 <- st_read("https://opendata.arcgis.com/datasets/38ba41dd74354563bce28a359b59324e_0.geojson") %>%
  filter(OFFENSE == "ROBBERY") %>%
  mutate(LATITUDE = as.numeric(LATITUDE),LONGITUDE = as.numeric(LONGITUDE)) %>% 
  dplyr::select(LATITUDE, LONGITUDE) %>%
  na.omit() %>%
  st_as_sf(coords = c("LATITUDE", "LONGITUDE"), crs = 4326, agr = "constant")%>%
  st_transform('ESRI:102685') %>%
  distinct() %>%
   .[fishnet,] #idk what this line does??

```

```{r}
burg_ppp <- as.ppp(st_coordinates(robberies), W = st_bbox(final_net))

#spatstat.options(npixel=c(1000,1000))
burg_KD <- spatstat::density.ppp(burg_ppp, 1000)

burg_KDE_sf <- as.data.frame(burg_KD) %>%
  st_as_sf(coords = c("x", "y"), crs = st_crs(final_net)) %>%
  aggregate(., final_net, mean) %>%
  mutate(label = "Kernel Density",
         Risk_Category = ntile(value, 100),
         Risk_Category = case_when(
           Risk_Category >= 90 ~ "90% to 100%",
           Risk_Category >= 70 & Risk_Category <= 89 ~ "70% to 89%",
           Risk_Category >= 50 & Risk_Category <= 69 ~ "50% to 69%",
           Risk_Category >= 30 & Risk_Category <= 49 ~ "30% to 49%",
           Risk_Category >= 1 & Risk_Category <= 29 ~ "1% to 29%")) %>%
  cbind(
    aggregate(
      dplyr::select(robberies18) %>% mutate(burgCount = 1), ., sum) %>%
    mutate(burgCount = replace_na(burgCount, 0))) %>%
  dplyr::select(label, Risk_Category, burgCount)
```

```{r}
burg_risk_sf <-
  filter(reg.summary, Regression == "Spatial LOGO-CV: Spatial Process") %>%
  mutate(label = "Risk Predictions",
         Risk_Category = ntile(Prediction, 100),
         Risk_Category = case_when(
           Risk_Category >= 90 ~ "90% to 100%",
           Risk_Category >= 70 & Risk_Category <= 89 ~ "70% to 89%",
           Risk_Category >= 50 & Risk_Category <= 69 ~ "50% to 69%",
           Risk_Category >= 30 & Risk_Category <= 49 ~ "30% to 49%",
           Risk_Category >= 1 & Risk_Category <= 29 ~ "1% to 29%")) %>%
  cbind(
    aggregate(
      dplyr::select(robberies18) %>% mutate(burgCount = 1), ., sum) %>%
      mutate(burgCount = replace_na(burgCount, 0))) %>%
  dplyr::select(label,Risk_Category, burgCount)
```

```{r}
rbind(burg_KDE_sf, burg_risk_sf) %>%
  na.omit() %>%
  gather(Variable, Value, -label, -Risk_Category, -geometry) %>%
  ggplot() +
    geom_sf(aes(fill = Risk_Category), colour = NA) +
    geom_sf(data = sample_n(robberies18, 750), size = .5, colour = "black") +
    facet_wrap(~label, ) +
    scale_fill_viridis(discrete = TRUE) +
    labs(title="Comparison of Kernel Density and Risk Predictions",
         subtitle="2017 robbery risk predictions; 2018 robberies") +
    mapTheme()
```


# The bar plot making this comparison.


# Two paragraphs on why or why not you would recommend your algorithm be put into production.

